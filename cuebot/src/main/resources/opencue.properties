cue.proxy = tcp -h cuetest01-vm -p 9019 -t 10000:tcp -h cuetest02-vm -p 9019 -t 10000:tcp -h cuetest03-vm -p 9019 -t 10000
spring.velocity.checkTemplateLocation=false

datasource.cue-data-source.driver-class-name=org.postgresql.Driver
datasource.cue-data-source.jdbc-url=jdbc:postgresql://dbhost/dbname
datasource.cue-data-source.username=cue
datasource.cue-data-source.password=password
# Discard connections after 6 hours, this allows for gradual
# connection rebalancing.
datasource.cue-data-source.maxAge=21600000

grpc.cue_port=${CUEBOT_GRPC_CUE_PORT:8443}
grpc.rqd_server_port=${CUEBOT_GRPC_RQD_SERVER_PORT:8444}
grpc.max_message_bytes=104857600
# Number of entries allowed in the RQD channel cache
grpc.rqd_cache_size=2000
# RQD Channel Cache Expiration in Minutes
grpc.rqd_cache_expiration=5
# RQD Channel Cache expected concurrency
grpc.rqd_cache_concurrency=20
# RQD Channel task deadline in seconds
grpc.rqd_task_deadline=10

# Healthy Threadpool Executor
booking_queue.threadpool.health_threshold=10
booking_queue.threadpool.core_pool_size=10
booking_queue.threadpool.max_pool_size=14
booking_queue.threadpool.queue_capacity=2000
dispatch.threadpool.core_pool_size=6
dispatch.threadpool.max_pool_size=8
dispatch.threadpool.queue_capacity=2000
healthy_threadpool.health_threshold=6
healthy_threadpool.min_unhealthy_period_min=3
report_queue.threadPoolSizeInitial=6
report_queue.threadPoolSizeMax=12
# The queue size should be bigger then the expected amount of hosts
report_queue.queueSize=5000
kill_queue.threadPoolSizeInitial=2
kill_queue.threadPoolSizeMax=6
kill_queue.queueSize=1000

# Turn on/off jobCompletion mailing module
mailing.enabled=true

# Whether or not to enable publishing to a messaging topic.
# Set to a boolean value. See com/imageworks/spcue/services/JmsMover.java.
messaging.enabled=false

# Default root directory for which logs will be stored if no other OS is defined.
# See com/imageworks/spcue/util/JobLogUtil.java.
# Override this via environment variable (CUE_FRAME_LOG_DIR) or command line flag
# (--log.frame-log-root.default_os). Command line flag will be preferred if both are provided.
log.frame-log-root.default_os=${CUE_FRAME_LOG_DIR:/shots}
# To set up root directories for other OS create new environment
# variable as `log.frame-log-root.[OS] where OS relates to str_os on the job table
# For example:
#   - log.frame-log-root.linux=${CUE_FRAME_LOG_DIR:/shots}
#   - log.frame-log-root.Windows=${CUE_FRAME_LOG_DIR:/S:}
# Note that for Windows, either forward or back slashes will work. However if CUE_FRAME_LOG_DIR is empty
# and S directory is in the root, the path will be broken due to the slash in front of S. Hence, if you
# are planning to use a folder in the root, use:
#   - log.frame-log-root.Windows=${S:}

# Maximum number of jobs to query.
dispatcher.job_query_max=20
# Number of seconds before waiting to book the same job from a different host.
# "0" disables the job_lock
dispatcher.job_lock_expire_seconds=20
# Concurrency level to allow on the job lock cache
dispatcher.job_lock_concurrency_level=14
# Maximum number of frames to query from the DB to attempt to dispatch.
dispatcher.frame_query_max=20
# Maximum number of frames to book at one time on the same host.
dispatcher.job_frame_dispatch_max=8
# Maximum number of frames to dispatch from a host at one time.
dispatcher.host_frame_dispatch_max=12
# Choose between different scheduling strategies:
#  - PRIORITY_ONLY: Sort by priority only
#  - FIFO: Whether or not to enable FIFO scheduling in the same priority.
#  - BALANCED: Use a rank formula that takes into account time waiting, and number
#      of cores required: rank = priority + (100 * (1 - (job.cores/job.int_min_cores))) + age in days
#      layer limiting is also disabled in this mode for performance reasons
dispatcher.scheduling_mode=PRIORITY_ONLY

# Number of threads to keep in the pool for launching job.
dispatcher.launch_queue.core_pool_size=1
# Maximum number of threads to allow in the pool for launching job.
dispatcher.launch_queue.max_pool_size=1
# Queue capacity for launching job.
dispatcher.launch_queue.queue_capacity=100

# Number of threads to keep in the pool for various operation.
dispatcher.dispatch_pool.core_pool_size=4
# Maximum number of threads to allow in the pool for various operation.
dispatcher.dispatch_pool.max_pool_size=4
# Queue capacity for various operation.
dispatcher.dispatch_pool.queue_capacity=500

# Number of threads to keep in the pool for management operation.
dispatcher.manage_pool.core_pool_size=8
# Maximum number of threads to allow in the pool for management operation.
dispatcher.manage_pool.max_pool_size=8
# Queue capacity for management operation.
dispatcher.manage_pool.queue_capacity=250

# Number of threads to keep in the pool for handling Host Report.
dispatcher.report_queue.core_pool_size=6
# Maximum number of threads to allow in the pool for handling Host Report.
dispatcher.report_queue.max_pool_size=8
# Queue capacity for handling Host Report.
dispatcher.report_queue.queue_capacity=1000

# Number of threads to keep in the pool for kill frame operation.
dispatcher.kill_queue.core_pool_size=6
# Maximum number of threads to allow in the pool for kill frame operation.
dispatcher.kill_queue.max_pool_size=8
# Queue capacity for kill frame operation.
dispatcher.kill_queue.queue_capacity=1000

# Number of threads to keep in the pool for booking.
dispatcher.booking_queue.core_pool_size=6
# Maximum number of threads to allow in the pool for booking.
dispatcher.booking_queue.max_pool_size=6
# Queue capacity for booking.
dispatcher.booking_queue.queue_capacity=1000

# Whether or not to satisfy dependents (*_ON_FRAME and *_ON_LAYER) only on Frame success
depend.satisfy_only_on_frame_success=true

# Jobs will be archived to the history tables after being completed for this long.
history.archive_jobs_cutoff_hours=72

# Delete down hosts automatically.
maintenance.auto_delete_down_hosts=false

# Set hostname/IP of the smtp host. Will be used for mailing
smtp_host=smtp

# These shows won't be deactivated by the scheduled tasks
protected_shows=pipe,swtest,edu

# These flags determine whether or not layers/frames will be readonly when job is finished.
# If flags are set as true, layers/frames cannot be retried, eaten, edited dependency on, etc.
# In order to toggle the same functionility on cuegui side, set flags in cue_resources.yaml
layer.finished_jobs_readonly=false
frame.finished_jobs_readonly=false