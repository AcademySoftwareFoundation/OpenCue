# Meeting Notes July 31, 2019

Secretary: Brian Cipriano

Attended: Brian Cipriano, Greg Denton, Benjamin Dines, Todd Prives,
  Alex Schworer, Erik Strauss, a few other non-TSC guests

This meeting was held in-person at SIGGRAPH 2019. A few other interested
SIGGRAPH attendees were present -- the meeting was open to everyone
regardless of TSC membership, as all TSC meetings are. 

- Current work
  - Brian
    - CI migration improvements. 30->15min build, still needs work
    - CII badge progress
      - Initial pass done. 83%
      - Big items: static analysis, test coverage
      - Small items: warning flags in the compiler
  - Greg
    - License limits
      - initial pieces in review, will get merged after siggraph
    - Plugins system
      - will resume work after siggraph
      - first task is scheduled plugins
      - then will look at event-driven plugins
  - Matt
    - Not at Siggraph
  - Any other in-progress work?
    - No
- Impressions from BoF
  - FRs from BoF notes:
    - Windows support
      - Very much an active blocker for potential users
    - Asset integration — scheduler to send jobs where the data already is
      if possible
    - Bad frame detection
    - DAG for job submissions, expand CueSubmit
    - Auto-kill feature in RQD
    - Log file streaming and auto alert on regex
    - REST API
    - Metrics / telemetry
      - What do we want to measure?
      - Measure the performance of an individual job/frame, as well as compared
        to the system profile
      - The job profile can be used to inform and optimize job requirements
      - Don't reinvent the wheel, there are good options for metrics collection
        already
      - Integrating with prometheus would be a good start. Netflix Atlas also
        a good option
      - Should be tightly integrated with RQD to associate job/process
        information is associated with timeseries data
      - Need to be able to get a farm-level view as well — e.g. see what was
        running when filesystem performance was suffering
      - Preemption rate is a key thing to track for anyone using cloud
    - A/B testing system
      - Ability to selectively change job options to compare results
      - Change submission parameters, type of host, etc.
      - You could currently just run two jobs, but it's very hard to make sure
        all parameters stay constant except for a few small changes. Job could
        get sent to slightly different hosts with older CPUs, for example
    - Adaptive scheduling
      - Could use a preprocess to determine scheduling readiness
      - Should assume this is a black box, many different types of work could
        happen here
      - Could be long-running, so it should be a two-step process --
        "get ready" then later "I'm ready", which could be a push or pull
  - Resource requirements
    - Add doc on the site on this
    - Important to show how requirements adjust to scale
    - Ben will collect some info on what SPI is using internally
  - Describe architecture examples — on premise, cloud, hybrid
    - Storage a key part of this
  - Job description could be standardized
    - We need more explanation of what outline is how it works
  - Discussion on controlling cloud costs — is this something the scheduler
    can help with somehow?
    - Normalizing all machines (on-prem and cloud) to provide a standard
      "computing unit" would be a good first step
