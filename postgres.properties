# Some useful links
# https://www.postgresql.org/docs/current/runtime-config-resource.html

# https://www.enterprisedb.com/postgres-tutorials/how-tune-postgresql-memory

# Autovacuum Settings : I have performed few autovacuum settings. Make Sure autovacuum is on.

autovacuum = on                 # Enable autovacuum subprocess?  'on'
                                        # requires track_counts to also be on.
#log_autovacuum_min_duration = -1       # -1 disables, 0 logs all actions and
# I'm logging autovacuum info in log file. This give more details in logfile when troubleshooting performance
log_autovacuum_min_duration = 0         # -1 disables, 0 logs all actions and
                                        # their durations, > 0 logs only
                                        # actions running at least this number
                                        # of milliseconds.
#autovacuum_max_workers = 3             # max number of autovacuum subprocesses
# I have changed default number of workers assigned for autovacuum. It depends how many cores you have. In my case I have 32 cores available and I'm assigning 6 for autovacuum workers.
autovacuum_max_workers = 6              # max number of autovacuum subprocesses
                                        # (change requires restart)
#autovacuum_naptime = 1min              # time between autovacuum runs
# I have changed autovacuum naptime, changing frequency on how frequently autovacuum process would be invoked. Making it more aggressive.
autovacuum_naptime = 30         # time between autovacuum runs
#autovacuum_vacuum_threshold = 50       # min number of row updates before
                                        # vacuum
#autovacuum_analyze_threshold = 50      # min number of row updates before
                                        # analyze
autovacuum_vacuum_scale_factor = 0.2    # fraction of table size before vacuum
#autovacuum_analyze_scale_factor = 0.1  # fraction of table size before analyze
# I have changed this setting to analyze automatically when there is 5% change in table.
autovacuum_analyze_scale_factor = 0.05  # fraction of table size before analyze
#autovacuum_freeze_max_age = 200000000  # maximum XID age before forced vacuum
                                        # (change requires restart)
#autovacuum_multixact_freeze_max_age = 400000000        # maximum multixact age
                                        # before forced vacuum
                                        # (change requires restart)
autovacuum_vacuum_cost_delay = 2ms      # default vacuum cost delay for
                                        # autovacuum, in milliseconds;
                                        # -1 means use vacuum_cost_delay
#autovacuum_vacuum_cost_limit = -1      # default vacuum cost limit for
autovacuum_vacuum_cost_limit = 2000     # default vacuum cost limit for
                                        # autovacuum, -1 means use
                                        # vacuum_cost_limit

# I have changed default_statistics_target to 500. It depends on how much data you have and how frequently you are analyzing tables. higher settings get a bigger sample of data which is used by query planner. 500 or less is recommended value. if there is a single table which need a bigger sample of stats that can be done on per table basis.
default_statistics_target = 500


# auto is default setting and its recommended to use auto. I didn't have much luck using force_custom_plan
plan_cache_mode = auto

# I have changed work_mem setting. I'm performing a gather of *_history table data into csv which performs a heavy sort operation. It depends how heavy sort operation you use. I'm attaing link to EDb site which have good info on how to tune it. This depends on how much memory and connections you have. I don't recommend setting it this high unless you do havy sort operations. 64mb is good for general environment.
work_mem = 256MB


# shared_buffers. recommended settings are between 15% to 25% of total machine ram.
shared_buffers = 53040MB

# maintenance_work_mem helps in maintenance operations like vacuum,create index stuff. it depends how much ram you have and how much you want to spare for maintenance_work_mem. let's say if I have 6 autovacuum processes then 6x3=18gb would be used by autovacuum runs. so careful when setting this memory. otherwise you can control autovacuum using  autovacuum_work_mem
maintenance_work_mem = 3GB

# you can set this value using formula (ram * 0.7)
effective_cache_size = 89120MB

# it depends how many connections your application throw.
max_connections = 700
# I set max_worker_processes to 32 which is equivalent to number of cores I have . If your server is dedicated you can set it to quivalent to number of cores available on system.
max_worker_processes=32
# max_parallel_worker is dependent on max_worker_process. max_parallel_worker should not be higner than max_worker_processes
max_parallel_workers=32

# These parameters depeneds on max_parallel_workers. Tune it carefully.
max_parallel_maintenance_workers = 4    # taken from max_parallel_workers
max_parallel_workers_per_gather = 8     # taken from max_parallel_workers


###
# Carefully tune following parameters for planner cost, it depends on the workload. Try to start with defaults first.

seq_page_cost = 1.0                     # measured on an arbitrary scale
random_page_cost = 1.1                  # same scale as above
cpu_tuple_cost = 0.01
cpu_index_tuple_cost = 0.005            # same scale as above

###
# I changed this parameter. it depends if you are using a standby server and your workload on how frequently wal is recycled.
# https://postgresqlco.nf/doc/en/param/wal_keep_size/
wal_keep_size = 8192


# Some settings on table level. Sometime autovacuum settings on analyze scale factor of 5% change on table will not help you in query planner. you can adjust such behavior using altering the analyze threshold level on number of tuples changed. It depends on your workload. Job table is frequently used and updated so autovacuum scale factor is disabled and instead a threshold of 300 is used on table level change.
ALTER TABLE job SET (
  autovacuum_analyze_scale_factor = 0.0,
  autovacuum_analyze_threshold = 300
);